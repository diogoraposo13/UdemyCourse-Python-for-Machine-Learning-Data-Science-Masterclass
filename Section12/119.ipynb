{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2bdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a916bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3fb430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e4e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales',axis=1)\n",
    "y = df['sales']\n",
    "\n",
    "#TRAIN TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "#SCALE DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab52817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e955ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953cc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_net_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d233a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0,1,1,5,10,50,100],'l1_ratio':[.1,.5,.7,.95,.99,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba0820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9830d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator=base_elastic_net_model,param_grid=param_grid,scoring='neg_mean_squared_error',cv=5,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd53bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\diogo\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 3.684e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0, 1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5efc1139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0, l1_ratio=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0, l1_ratio=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0, l1_ratio=0.1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f54577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0, 'l1_ratio': 0.1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2abbac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.1}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.5}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.7}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.95}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.99}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 1}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-9.827475</td>\n",
       "      <td>-5.261525</td>\n",
       "      <td>-11.875347</td>\n",
       "      <td>-7.449195</td>\n",
       "      <td>-8.542329</td>\n",
       "      <td>-8.591174</td>\n",
       "      <td>2.222939</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-8.707071</td>\n",
       "      <td>-4.214228</td>\n",
       "      <td>-10.879261</td>\n",
       "      <td>-6.204545</td>\n",
       "      <td>-7.173031</td>\n",
       "      <td>-7.435627</td>\n",
       "      <td>2.255532</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-7.920870</td>\n",
       "      <td>-3.549562</td>\n",
       "      <td>-10.024877</td>\n",
       "      <td>-5.379553</td>\n",
       "      <td>-6.324836</td>\n",
       "      <td>-6.639940</td>\n",
       "      <td>2.206213</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-6.729435</td>\n",
       "      <td>-2.591285</td>\n",
       "      <td>-8.709842</td>\n",
       "      <td>-4.156317</td>\n",
       "      <td>-5.329916</td>\n",
       "      <td>-5.503359</td>\n",
       "      <td>2.102835</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-6.521344</td>\n",
       "      <td>-2.431385</td>\n",
       "      <td>-8.471086</td>\n",
       "      <td>-3.946327</td>\n",
       "      <td>-5.151344</td>\n",
       "      <td>-5.304297</td>\n",
       "      <td>2.079945</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>-6.468807</td>\n",
       "      <td>-2.391483</td>\n",
       "      <td>-8.410171</td>\n",
       "      <td>-3.893566</td>\n",
       "      <td>-5.105922</td>\n",
       "      <td>-5.253990</td>\n",
       "      <td>2.073832</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-9.827475</td>\n",
       "      <td>-5.261525</td>\n",
       "      <td>-11.875347</td>\n",
       "      <td>-7.449195</td>\n",
       "      <td>-8.542329</td>\n",
       "      <td>-8.591174</td>\n",
       "      <td>2.222939</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-8.707071</td>\n",
       "      <td>-4.214228</td>\n",
       "      <td>-10.879261</td>\n",
       "      <td>-6.204545</td>\n",
       "      <td>-7.173031</td>\n",
       "      <td>-7.435627</td>\n",
       "      <td>2.255532</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-7.920870</td>\n",
       "      <td>-3.549562</td>\n",
       "      <td>-10.024877</td>\n",
       "      <td>-5.379553</td>\n",
       "      <td>-6.324836</td>\n",
       "      <td>-6.639940</td>\n",
       "      <td>2.206213</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-6.729435</td>\n",
       "      <td>-2.591285</td>\n",
       "      <td>-8.709842</td>\n",
       "      <td>-4.156317</td>\n",
       "      <td>-5.329916</td>\n",
       "      <td>-5.503359</td>\n",
       "      <td>2.102835</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-6.521344</td>\n",
       "      <td>-2.431385</td>\n",
       "      <td>-8.471086</td>\n",
       "      <td>-3.946327</td>\n",
       "      <td>-5.151344</td>\n",
       "      <td>-5.304297</td>\n",
       "      <td>2.079945</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>-6.468807</td>\n",
       "      <td>-2.391483</td>\n",
       "      <td>-8.410171</td>\n",
       "      <td>-3.893566</td>\n",
       "      <td>-5.105922</td>\n",
       "      <td>-5.253990</td>\n",
       "      <td>2.073832</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.1}</td>\n",
       "      <td>-22.979265</td>\n",
       "      <td>-15.547104</td>\n",
       "      <td>-23.668249</td>\n",
       "      <td>-19.921063</td>\n",
       "      <td>-16.262737</td>\n",
       "      <td>-19.675684</td>\n",
       "      <td>3.334901</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.5}</td>\n",
       "      <td>-27.793488</td>\n",
       "      <td>-18.602269</td>\n",
       "      <td>-27.107849</td>\n",
       "      <td>-23.945227</td>\n",
       "      <td>-18.064635</td>\n",
       "      <td>-23.102694</td>\n",
       "      <td>4.108297</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.7}</td>\n",
       "      <td>-29.655510</td>\n",
       "      <td>-21.085059</td>\n",
       "      <td>-29.629478</td>\n",
       "      <td>-26.724595</td>\n",
       "      <td>-20.223654</td>\n",
       "      <td>-25.463659</td>\n",
       "      <td>4.077877</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>-27.385346</td>\n",
       "      <td>-19.159534</td>\n",
       "      <td>-27.635464</td>\n",
       "      <td>-24.154104</td>\n",
       "      <td>-18.968161</td>\n",
       "      <td>-23.460522</td>\n",
       "      <td>3.794608</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>100</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.001588      0.000804         0.001029        0.000035           0   \n",
       "1        0.001060      0.000335         0.000402        0.000493           0   \n",
       "2        0.001559      0.000393         0.000200        0.000400           0   \n",
       "3        0.001109      0.000162         0.000505        0.000451           0   \n",
       "4        0.001098      0.000103         0.000206        0.000413           0   \n",
       "5        0.001029      0.000298         0.000429        0.000526           0   \n",
       "6        0.001015      0.000534         0.000400        0.000489           1   \n",
       "7        0.000809      0.000405         0.000437        0.000538           1   \n",
       "8        0.000822      0.000413         0.000202        0.000403           1   \n",
       "9        0.001182      0.000222         0.000101        0.000202           1   \n",
       "10       0.001002      0.000005         0.000000        0.000000           1   \n",
       "11       0.000200      0.000400         0.000255        0.000511           1   \n",
       "12       0.000502      0.000449         0.000000        0.000000           1   \n",
       "13       0.000659      0.000544         0.000200        0.000400           1   \n",
       "14       0.000303      0.000403         0.000600        0.000490           1   \n",
       "15       0.001102      0.000202         0.000000        0.000000           1   \n",
       "16       0.000401      0.000491         0.000200        0.000400           1   \n",
       "17       0.000502      0.000448         0.000199        0.000397           1   \n",
       "18       0.000201      0.000401         0.000893        0.000490           5   \n",
       "19       0.000600      0.000490         0.000400        0.000490           5   \n",
       "20       0.000600      0.000490         0.000000        0.000000           5   \n",
       "21       0.000200      0.000400         0.000800        0.000400           5   \n",
       "22       0.000301      0.000401         0.000721        0.000612           5   \n",
       "23       0.000405      0.000590         0.000631        0.000518           5   \n",
       "24       0.000600      0.000490         0.000401        0.000491          10   \n",
       "25       0.000588      0.000779         0.000000        0.000000          10   \n",
       "26       0.000571      0.000537         0.000558        0.000519          10   \n",
       "27       0.000864      0.000440         0.000303        0.000403          10   \n",
       "28       0.000101      0.000202         0.000943        0.000515          10   \n",
       "29       0.000713      0.000605         0.000207        0.000414          10   \n",
       "30       0.000303      0.000403         0.000399        0.000488          50   \n",
       "31       0.000864      0.000518         0.000400        0.000490          50   \n",
       "32       0.000902      0.000503         0.000400        0.000490          50   \n",
       "33       0.001017      0.000058         0.000312        0.000393          50   \n",
       "34       0.000600      0.000490         0.000400        0.000490          50   \n",
       "35       0.000766      0.000693         0.000664        0.000555          50   \n",
       "36       0.000236      0.000472         0.000558        0.000512         100   \n",
       "37       0.000401      0.000491         0.000000        0.000000         100   \n",
       "38       0.000502      0.000448         0.000499        0.000631         100   \n",
       "39       0.000801      0.000400         0.000201        0.000403         100   \n",
       "40       0.000921      0.000515         0.000202        0.000404         100   \n",
       "41       0.000504      0.000449         0.000000        0.000000         100   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_score  \\\n",
       "0             0.1     {'alpha': 0, 'l1_ratio': 0.1}          -3.139328   \n",
       "1             0.5     {'alpha': 0, 'l1_ratio': 0.5}          -3.139328   \n",
       "2             0.7     {'alpha': 0, 'l1_ratio': 0.7}          -3.139328   \n",
       "3            0.95    {'alpha': 0, 'l1_ratio': 0.95}          -3.139328   \n",
       "4            0.99    {'alpha': 0, 'l1_ratio': 0.99}          -3.139328   \n",
       "5               1       {'alpha': 0, 'l1_ratio': 1}          -3.139328   \n",
       "6             0.1     {'alpha': 1, 'l1_ratio': 0.1}          -9.827475   \n",
       "7             0.5     {'alpha': 1, 'l1_ratio': 0.5}          -8.707071   \n",
       "8             0.7     {'alpha': 1, 'l1_ratio': 0.7}          -7.920870   \n",
       "9            0.95    {'alpha': 1, 'l1_ratio': 0.95}          -6.729435   \n",
       "10           0.99    {'alpha': 1, 'l1_ratio': 0.99}          -6.521344   \n",
       "11              1       {'alpha': 1, 'l1_ratio': 1}          -6.468807   \n",
       "12            0.1     {'alpha': 1, 'l1_ratio': 0.1}          -9.827475   \n",
       "13            0.5     {'alpha': 1, 'l1_ratio': 0.5}          -8.707071   \n",
       "14            0.7     {'alpha': 1, 'l1_ratio': 0.7}          -7.920870   \n",
       "15           0.95    {'alpha': 1, 'l1_ratio': 0.95}          -6.729435   \n",
       "16           0.99    {'alpha': 1, 'l1_ratio': 0.99}          -6.521344   \n",
       "17              1       {'alpha': 1, 'l1_ratio': 1}          -6.468807   \n",
       "18            0.1     {'alpha': 5, 'l1_ratio': 0.1}         -22.979265   \n",
       "19            0.5     {'alpha': 5, 'l1_ratio': 0.5}         -27.793488   \n",
       "20            0.7     {'alpha': 5, 'l1_ratio': 0.7}         -29.655510   \n",
       "21           0.95    {'alpha': 5, 'l1_ratio': 0.95}         -31.130307   \n",
       "22           0.99    {'alpha': 5, 'l1_ratio': 0.99}         -31.130307   \n",
       "23              1       {'alpha': 5, 'l1_ratio': 1}         -31.130307   \n",
       "24            0.1    {'alpha': 10, 'l1_ratio': 0.1}         -27.385346   \n",
       "25            0.5    {'alpha': 10, 'l1_ratio': 0.5}         -31.130307   \n",
       "26            0.7    {'alpha': 10, 'l1_ratio': 0.7}         -31.130307   \n",
       "27           0.95   {'alpha': 10, 'l1_ratio': 0.95}         -31.130307   \n",
       "28           0.99   {'alpha': 10, 'l1_ratio': 0.99}         -31.130307   \n",
       "29              1      {'alpha': 10, 'l1_ratio': 1}         -31.130307   \n",
       "30            0.1    {'alpha': 50, 'l1_ratio': 0.1}         -31.130307   \n",
       "31            0.5    {'alpha': 50, 'l1_ratio': 0.5}         -31.130307   \n",
       "32            0.7    {'alpha': 50, 'l1_ratio': 0.7}         -31.130307   \n",
       "33           0.95   {'alpha': 50, 'l1_ratio': 0.95}         -31.130307   \n",
       "34           0.99   {'alpha': 50, 'l1_ratio': 0.99}         -31.130307   \n",
       "35              1      {'alpha': 50, 'l1_ratio': 1}         -31.130307   \n",
       "36            0.1   {'alpha': 100, 'l1_ratio': 0.1}         -31.130307   \n",
       "37            0.5   {'alpha': 100, 'l1_ratio': 0.5}         -31.130307   \n",
       "38            0.7   {'alpha': 100, 'l1_ratio': 0.7}         -31.130307   \n",
       "39           0.95  {'alpha': 100, 'l1_ratio': 0.95}         -31.130307   \n",
       "40           0.99  {'alpha': 100, 'l1_ratio': 0.99}         -31.130307   \n",
       "41              1     {'alpha': 100, 'l1_ratio': 1}         -31.130307   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           -1.622463          -5.373837          -2.242246   \n",
       "1           -1.622463          -5.373837          -2.242246   \n",
       "2           -1.622463          -5.373837          -2.242246   \n",
       "3           -1.622463          -5.373837          -2.242246   \n",
       "4           -1.622463          -5.373837          -2.242246   \n",
       "5           -1.622463          -5.373837          -2.242246   \n",
       "6           -5.261525         -11.875347          -7.449195   \n",
       "7           -4.214228         -10.879261          -6.204545   \n",
       "8           -3.549562         -10.024877          -5.379553   \n",
       "9           -2.591285          -8.709842          -4.156317   \n",
       "10          -2.431385          -8.471086          -3.946327   \n",
       "11          -2.391483          -8.410171          -3.893566   \n",
       "12          -5.261525         -11.875347          -7.449195   \n",
       "13          -4.214228         -10.879261          -6.204545   \n",
       "14          -3.549562         -10.024877          -5.379553   \n",
       "15          -2.591285          -8.709842          -4.156317   \n",
       "16          -2.431385          -8.471086          -3.946327   \n",
       "17          -2.391483          -8.410171          -3.893566   \n",
       "18         -15.547104         -23.668249         -19.921063   \n",
       "19         -18.602269         -27.107849         -23.945227   \n",
       "20         -21.085059         -29.629478         -26.724595   \n",
       "21         -22.549433         -31.155204         -27.963447   \n",
       "22         -22.549433         -31.155204         -27.963447   \n",
       "23         -22.549433         -31.155204         -27.963447   \n",
       "24         -19.159534         -27.635464         -24.154104   \n",
       "25         -22.549433         -31.155204         -27.963447   \n",
       "26         -22.549433         -31.155204         -27.963447   \n",
       "27         -22.549433         -31.155204         -27.963447   \n",
       "28         -22.549433         -31.155204         -27.963447   \n",
       "29         -22.549433         -31.155204         -27.963447   \n",
       "30         -22.549433         -31.155204         -27.963447   \n",
       "31         -22.549433         -31.155204         -27.963447   \n",
       "32         -22.549433         -31.155204         -27.963447   \n",
       "33         -22.549433         -31.155204         -27.963447   \n",
       "34         -22.549433         -31.155204         -27.963447   \n",
       "35         -22.549433         -31.155204         -27.963447   \n",
       "36         -22.549433         -31.155204         -27.963447   \n",
       "37         -22.549433         -31.155204         -27.963447   \n",
       "38         -22.549433         -31.155204         -27.963447   \n",
       "39         -22.549433         -31.155204         -27.963447   \n",
       "40         -22.549433         -31.155204         -27.963447   \n",
       "41         -22.549433         -31.155204         -27.963447   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -4.341671        -3.343909        1.366384                1  \n",
       "1           -4.341671        -3.343909        1.366384                1  \n",
       "2           -4.341671        -3.343909        1.366384                1  \n",
       "3           -4.341671        -3.343909        1.366384                1  \n",
       "4           -4.341671        -3.343909        1.366384                1  \n",
       "5           -4.341671        -3.343909        1.366384                1  \n",
       "6           -8.542329        -8.591174        2.222939               17  \n",
       "7           -7.173031        -7.435627        2.255532               15  \n",
       "8           -6.324836        -6.639940        2.206213               13  \n",
       "9           -5.329916        -5.503359        2.102835               11  \n",
       "10          -5.151344        -5.304297        2.079945                9  \n",
       "11          -5.105922        -5.253990        2.073832                7  \n",
       "12          -8.542329        -8.591174        2.222939               17  \n",
       "13          -7.173031        -7.435627        2.255532               15  \n",
       "14          -6.324836        -6.639940        2.206213               13  \n",
       "15          -5.329916        -5.503359        2.102835               11  \n",
       "16          -5.151344        -5.304297        2.079945                9  \n",
       "17          -5.105922        -5.253990        2.073832                7  \n",
       "18         -16.262737       -19.675684        3.334901               19  \n",
       "19         -18.064635       -23.102694        4.108297               20  \n",
       "20         -20.223654       -25.463659        4.077877               22  \n",
       "21         -21.698192       -26.899317        4.077240               23  \n",
       "22         -21.698192       -26.899317        4.077240               23  \n",
       "23         -21.698192       -26.899317        4.077240               23  \n",
       "24         -18.968161       -23.460522        3.794608               21  \n",
       "25         -21.698192       -26.899317        4.077240               23  \n",
       "26         -21.698192       -26.899317        4.077240               23  \n",
       "27         -21.698192       -26.899317        4.077240               23  \n",
       "28         -21.698192       -26.899317        4.077240               23  \n",
       "29         -21.698192       -26.899317        4.077240               23  \n",
       "30         -21.698192       -26.899317        4.077240               23  \n",
       "31         -21.698192       -26.899317        4.077240               23  \n",
       "32         -21.698192       -26.899317        4.077240               23  \n",
       "33         -21.698192       -26.899317        4.077240               23  \n",
       "34         -21.698192       -26.899317        4.077240               23  \n",
       "35         -21.698192       -26.899317        4.077240               23  \n",
       "36         -21.698192       -26.899317        4.077240               23  \n",
       "37         -21.698192       -26.899317        4.077240               23  \n",
       "38         -21.698192       -26.899317        4.077240               23  \n",
       "39         -21.698192       -26.899317        4.077240               23  \n",
       "40         -21.698192       -26.899317        4.077240               23  \n",
       "41         -21.698192       -26.899317        4.077240               23  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "110b4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbac8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d9f4ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.298716697886379"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979468e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
